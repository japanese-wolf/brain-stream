# BrainStream 核心価値: 発見の加速

*2026-02-07 壁打ちセッション（11問）に基づく*

## 1. 核心的な気づき

### BrainStreamの真の価値は「知らないことを知らない」問題の解決

- 最大の競合は**LLMに直接聞くこと**（例: Claudeに「最近のAWSアップデートは？」と聞く）
- LLMに聞くには**何を聞くべきかを知っている必要がある**
- BrainStreamは**ユーザーが質問すら思いつかなかった情報を届ける**ツール
- RSS収集+要約はこの目的を達成する**手段**であり、それ自体が価値ではない

### アーキテクチャの妥当性

現在のアーキテクチャ（FastAPI + React + SQLite + プラグイン）は「発見の加速」という目的に対して過剰ではない:

- **SQLite + 記事蓄積** → 共起分析の基盤（記事を蓄積しないと統計的分析ができない）
- **プラグインシステム** → ソース追加の柔軟性（ソースが増えるほど発見の精度が向上）
- **FastAPI** → LLMのオンデマンド呼び出しに非同期IOが適切
- **React UI** → 「発見」の提示にはビジュアルが重要

## 2. 二方向の発見モデル

一人のユーザーは、ドメインごとに異なる習熟度を持つ。
例えば、AWS Lambdaでは先端を走りつつ、AI分野では追いつく側にいることがある。
そのため、同一ユーザーに対して両方向の発見を提供する必要がある。

### 方向A: 既知 → 未知（フィルタバブルを破る）

- **状況**: ユーザーがそのドメインで先端にいる
- **例**: Lambda の記事を読んでいたら「WASM ランタイムがサーバーレスに影響する」と知らなかった分野へ導かれる
- **目的**: 技術的視野を広げるセレンディピティ
- **実装方針**: 共起分析（ルールベース主体）、LLM不要または最小限
- **コスト**: 低（ローカル計算）

### 方向B: 未知 → 既知（理解を加速する）

- **状況**: ユーザーがそのドメインで追いつく側にいる
- **例**: WASM のニュースが流れてきた時「あなたの Lambda にこう影響する」と既知の技術との接続点を示す
- **目的**: 新しい情報を自分の文脈に落とし込むアンカリング
- **実装方針**: LLMプロンプト拡張、ユーザーのテックスタックが既知のため精度が出やすい
- **コスト**: 中（オンデマンドLLM）

## 3. 実装フェーズ

### Phase 1: LLMプロンプトの拡張（方向B）

現在の「AI Summarize」ボタンのプロンプトを拡張し、以下を追加:
- ユーザーのテックスタックとの具体的な関連性
- 関連技術の示唆（「この技術を使っているなら、これも知るべき」）
- 歴史的文脈（「過去にこのような技術が注目された時、業界はこう動いた」）

既存の仕組み（オンデマンドボタン）の上に乗せるため実装コストが低い。

### Phase 2: 共起分析基盤（方向A）

蓄積記事のタグ共起を分析し「注目の技術」を抽出するロジック:
- 記事タグの共起頻度を計算
- ユーザーのテックスタックに関連するが、テックスタック外の技術を特定
- フィードに「あなたの分野で関連性が高まっている技術」セクションを追加
- LLM不要、記事が蓄積されるほど精度が向上

### Phase 3: プロフィール拡張

ユーザーの関心モデルを「テックスタック」から拡張:
- 分野（例: サーバーレス、データエンジニアリング、MLOps）
- 役割（例: バックエンド、インフラ、フルスタック）
- 目標（例: 新規プロジェクトの技術選定、既存システムの最適化）

### Phase 4: READMEの更新

核心価値と発見モデルをREADMEに反映し、プロジェクトのビジョンを明確化。

## 4. 制約と判断基準

### トークンコストの管理方針

- 方向A（既知→未知）: ルールベース主体、LLMは使用しないか最小限
- 方向B（未知→既知）: オンデマンド（ユーザーが明示的に実行した時のみ）
- バッチ処理やスケジューラーによる自動LLM呼び出しは行わない

### 精度と信頼性

- 方向Bの精度はユーザーのテックスタックが既知のため出しやすい
- 方向Aの精度は記事の蓄積量に依存する
- LLMの推論が的外れだと信頼を失うため、理由の明示が重要

---

*この文書は、#22（関心ごとの拡張機能）の設計方針として作成されました。*
